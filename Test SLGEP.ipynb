{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "class ProbabilityModel:  # Works reliably for 2(+) Dimensional distributions\n",
    "    \"\"\" properties\n",
    "        modeltype; % multivariate normal ('mvarnorm' - for real coded) or univariate marginal distribution ('umd' - for binary coded)    \n",
    "        mean_noisy;\n",
    "        mean_true;\n",
    "        covarmat_noisy;\n",
    "        covarmat_true;\n",
    "        probofone_noisy;\n",
    "        probofone_true;\n",
    "        probofzero_noisy;\n",
    "        probofzero_true;    \n",
    "        vars;\n",
    "      end\"\"\"\n",
    "\n",
    "    def __init__(self, modeltype):\n",
    "        self.modeltype = modeltype\n",
    "        \n",
    "    def sample(self, nos):\n",
    "        # print('nos,self.vars', nos,self.vars)\n",
    "        nos = int(nos)\n",
    "        solutions = np.random.multivariate_normal(self.mean_true, self.covarmat_true, size=nos)\n",
    "        return solutions\n",
    "\n",
    "    def pdfeval(self, solutions):\n",
    "        \"\"\"Calculating the probabilty of every solution\n",
    "        \n",
    "        Arguments:\n",
    "            solutions {[2-D Array]} -- [solution or population of evolutionary algorithm]\n",
    "        \n",
    "        Returns:\n",
    "            [1-D Array] -- [probabilty of every solution]\n",
    "        \"\"\"\n",
    "\n",
    "        mvn = multivariate_normal(self.mean_noisy,self.covarmat_noisy)  \n",
    "        # create a multivariate Gaussian object with specified mean and covariance matrix\n",
    "        probofsols = mvn.pdf(solutions)\n",
    "        return probofsols\n",
    "\n",
    "    def buildmodel(self, solutions):\n",
    "        pop, self.vars = solutions.shape\n",
    "        self.mean_true = np.mean(solutions, 0)\n",
    "        # Tính ma trận hiệp phương sai của solutions. Ma trận hiệp phương sai có đường chéo chính là phương sai\n",
    "        # của các mẫu dữ liệu theo từng chiều\n",
    "        covariance = np.cov(solutions)\n",
    "        # Simplifying to univariate distribution by ignoring off diagonal terms of covariance matrix\n",
    "        # Giữ lại đường chéo chính của ma trận hiệp phương sai\n",
    "        self.covarmat_true = np.diag(np.diag(covariance))\n",
    "        # Thêm 10% noise để tránh overfit\n",
    "        self.solutions_noisy = np.append(solutions, np.random.rand(round(0.1 * pop), self.vars), 0)\n",
    "        self.mean_noisy = np.mean(self.solutions_noisy, 0)\n",
    "        covariance = np.cov(self.solutions_noisy)\n",
    "        # Simplifying to univariate distribution by ignoring off diagonal terms of covariance matrix\n",
    "        self.covarmat_noisy = np.diag(np.diag(covariance))\n",
    "        self.covarmat_noisy = np.cov(self.solutions_noisy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from slgep_lib import wrap_config\n",
    "from utils import Saver\n",
    "from cea import cea\n",
    "import argparse\n",
    "import yaml\n",
    "from tools import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Taskset:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        names = config['names']\n",
    "        self.config = config\n",
    "        self.envs = [gym.make(name) for name in names]\n",
    "\n",
    "    def run_episode(self, sf, policy_function):\n",
    "        env = self.envs[0]\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "        for i in range(18000):\n",
    "            action = policy_function(observation.astype(np.float32))\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return -total_reward\n",
    "\n",
    "    @property\n",
    "    def K(self):\n",
    "        return len(self.config['h_mains'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import namedtuple\n",
    "\n",
    "ChromosomeRange = namedtuple('ChromosomeRange', ('R1', 'R2', 'R3', 'R4'))\n",
    "# | --- Function Set --- | --- ADF Set --- | --- ADF Terminal Set --- | --- Terminals --- |\n",
    "# | 'function_set'       | 'adf_set'       | 'adf_terminal_set'       | 'terminal_set'    |\n",
    "# |                      |                 |        (Variables)       |     (Inputs)      |\n",
    "# 0 ---------------------| R1 -------------| R2 ----------------------| R3 ---------------| R4\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, index, arity, parent, chromosome_factory):\n",
    "        self.index = index\n",
    "        self.arity = arity\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.chromosome_factory = chromosome_factory\n",
    "\n",
    "    def _set_adfs_terminals(self, inputs):\n",
    "        config = self.chromosome_factory.config\n",
    "        for i in range(len(config['adf_terminal_set'])):\n",
    "            config['adf_terminal_set'][i]['value'] = inputs[i]\n",
    "\n",
    "    def get_value(self):\n",
    "        config = self.chromosome_factory.config\n",
    "        # Extract range\n",
    "        R1, R2, R3, R4 = self.chromosome_factory.chromosome_range\n",
    "        # If this node is a leaf, return its value\n",
    "        if self.index >= R3:\n",
    "            return config['terminal_set'][self.index - R3]['value']\n",
    "        if self.index >= R2:\n",
    "            return config['adf_terminal_set'][self.index - R2]['value']\n",
    "        # If this node is a function or ADF node, \n",
    "        # we need to pass in its children as params\n",
    "        params = []\n",
    "        for child in self.children:\n",
    "            value = child.get_value()\n",
    "            if np.isnan(value):\n",
    "                return float('nan')\n",
    "            params.append(child.get_value())\n",
    "        # If this node is an auto defined function\n",
    "        # Assign input to the ADF variables\n",
    "        if self.index >= R1:\n",
    "            self._set_adfs_terminals(params)\n",
    "            return config['adf_set'][self.index - R1]['func'].get_value()\n",
    "        # If this node is a normal function\n",
    "        function = config['function_set'][self.index]\n",
    "        return config['function_set'][self.index]['func'](*params)\n",
    "\n",
    "class ADF:\n",
    "\n",
    "    def __init__(self, gene, chromosome_factory):\n",
    "        self.gene = gene\n",
    "        self.root = None\n",
    "        self.chromosome_factory = chromosome_factory\n",
    "        self._parse()\n",
    "\n",
    "    def _parse(self):\n",
    "        config = self.chromosome_factory.config\n",
    "        symbols = config['function_set'] + config['adf_set'] + \\\n",
    "                  config['terminal_set'] + config['adf_terminal_set']\n",
    "\n",
    "        gene = deepcopy(self.gene).tolist()\n",
    "\n",
    "        # Assign root\n",
    "        self.root = Node(index=gene[0],\n",
    "                         arity=symbols[gene[0]]['arity'],\n",
    "                         parent=None,\n",
    "                         chromosome_factory=self.chromosome_factory)\n",
    "        queue = [self.root]\n",
    "        gene.pop(0)\n",
    "\n",
    "        # Traverse BFS to build tree\n",
    "        while len(queue) and len(gene):\n",
    "            parent = queue.pop(0)\n",
    "\n",
    "            for i in range(parent.arity):\n",
    "                node = Node(index=gene[0],\n",
    "                            arity=symbols[gene[0]]['arity'],\n",
    "                            parent=parent,\n",
    "                            chromosome_factory=self.chromosome_factory)\n",
    "                queue.append(node)\n",
    "                gene.pop(0)\n",
    "                parent.children.append(node)\n",
    "\n",
    "    def get_value(self):\n",
    "        return self.root.get_value()\n",
    "\n",
    "class ChromosomeFactory:\n",
    "\n",
    "    def __init__(self, _config):\n",
    "        self.config = _config\n",
    "        # Assign defined structure of the solution\n",
    "        config = _config\n",
    "        # Compute chromosome range\n",
    "        R1 = len(config['function_set'])\n",
    "        R2 = R1 + len(config['adf_set'])\n",
    "        R3 = R2 + len(config['adf_terminal_set'])\n",
    "        R4 = R3 + len(config['terminal_set'])\n",
    "        self.chromosome_range = ChromosomeRange(R1, R2, R3, R4)\n",
    "\n",
    "    def _get_feasible_range(self, i):\n",
    "        R1, R2, R3, R4 = self.chromosome_range\n",
    "        config = self.config\n",
    "        # gene at i belong to one of the given mains\n",
    "        if i < config['num_main'] * (config['h_main'] + config['l_main']):\n",
    "            if i % (config['h_main'] + config['l_main']) < config['h_main']:\n",
    "                # Head of main: adf_set and function_set\n",
    "                return 0, R2\n",
    "            else:\n",
    "                # Tail of main: terminal_set\n",
    "                return R3, R4\n",
    "        if (i - config['num_main'] * (config['h_main'] + config['l_main'])) % \\\n",
    "                (config['h_adf'] + config['l_adf']) < config['h_adf']:\n",
    "            # Head of ADF: function_set\n",
    "            return 0, R1\n",
    "        else:\n",
    "            # Tail of ADF: adf_terminal_set\n",
    "            return R2, R3\n",
    "\n",
    "    def initialize(self):\n",
    "        config = self.config\n",
    "        population = np.empty([config['pop_size'] * config['K'] * 2, config['dim']])\n",
    "        for j in range(config['dim']):\n",
    "            low, high = self._get_feasible_range(j)\n",
    "            population[:, j] = np.random.randint(low, high, size=config['pop_size'] * config['K'] * 2)\n",
    "        return population.astype(np.int32)\n",
    "\n",
    "    def parse(self, chromosome):\n",
    "        # Parse the auto defined functions\n",
    "        config = self.config\n",
    "        for i in range(config['num_adf']):\n",
    "            head = config['num_main'] * (config['h_main'] + config['l_main']) + \\\n",
    "                   i * (config['h_adf'] + config['l_adf'])\n",
    "            tail = head + config['h_adf'] + config['l_adf']\n",
    "            config['adf_set'][i]['func'] = ADF(chromosome[head:tail], self)\n",
    "\n",
    "        # Parse the main program\n",
    "        for i in range(config['num_main']):\n",
    "            head = i * (config['h_main'] + config['l_main'])\n",
    "            tail = head + config['h_main'] + config['l_main']\n",
    "            config['main'].append(ADF(chromosome[head:tail], self))\n",
    "\n",
    "    def _set_main_terminals(self, inputs):\n",
    "        config = self.config\n",
    "        for i in range(len(config['terminal_set'])):\n",
    "            config['terminal_set'][i]['value'] = inputs[i]\n",
    "\n",
    "    def get_value(self, inputs):\n",
    "        config = self.config\n",
    "        self._set_main_terminals(inputs)\n",
    "        outputs = []\n",
    "        for i in range(config['num_main']):\n",
    "            outputs.append(config['main'][i].get_value())\n",
    "        return outputs\n",
    "\n",
    "    def get_action(self, inputs):\n",
    "        config = self.config\n",
    "        self._set_main_terminals(inputs)\n",
    "        outputs = []\n",
    "        for i in range(config['num_main']):\n",
    "            outputs.append(config['main'][i].get_value())\n",
    "        outputs = np.array(outputs)\n",
    "        outputs[np.where(outputs == np.nan)[0]] = -np.inf\n",
    "        return np.argmax(outputs)\n",
    "\n",
    "    def one_point_crossover(self, pa, pb):\n",
    "        D = len(pa)\n",
    "        index = np.random.randint(low=1, high=D-1)\n",
    "        ca = np.empty_like(pa)\n",
    "        cb = np.empty_like(pa)\n",
    "\n",
    "        ca = np.concatenate([pa[:index], pb[index:]])\n",
    "        cb = np.concatenate([pb[:index], pb[index:]])\n",
    "        return ca, cb\n",
    "\n",
    "    def _get_crossover_range(self, i):\n",
    "        config = self.config\n",
    "        n, h, l = config['num_main'], config['h_main'], config['l_main']\n",
    "        n_adf, h_adf, l_adf = config['num_adf'], config['h_adf'], config['l_adf']\n",
    "        if i < n * (h + l):\n",
    "            if i % (l + h) == 0:\n",
    "                low = (i / (h + l) - 1) * (h + l)\n",
    "                high = (i / (h + l) + 1) * (h + l)\n",
    "            else:\n",
    "                low = np.floor(i / (h + l)) * (h + l)\n",
    "                high = np.ceil(i / (h + l)) * (h + l)\n",
    "        else:\n",
    "            j = i - n * (h + l)\n",
    "            if j % (l_adf + h_adf) == 0:\n",
    "                low = (j / (h_adf + l_adf) - 1) * (h_adf + l_adf)\n",
    "                high = (j / (h_adf + l_adf) + 1) * (h_adf + l_adf)\n",
    "            else:\n",
    "                low = np.floor(j / (h_adf + l_adf)) * (h_adf + l_adf)\n",
    "                high = np.ceil(j / (h_adf + l_adf)) * (h_adf + l_adf)\n",
    "            low += n * (h + l)\n",
    "            high += n * (h + l)\n",
    "        return int(low), int(high)\n",
    "\n",
    "    def one_point_crossover_adf(self, pa, pb):\n",
    "        D = len(pa)\n",
    "        i = np.random.randint(low=1, high=D-1)\n",
    "        low, high = self._get_crossover_range(i)\n",
    "        ca = deepcopy(pa)\n",
    "        cb = deepcopy(pa)\n",
    "        if np.random.rand() < 0.5:\n",
    "            ca[low:i] = pb[low:i]\n",
    "            cb[low:i] = pa[low:i]\n",
    "        else:\n",
    "            ca[i:high] = pb[i:high]\n",
    "            cb[i:high] = pa[i:high]\n",
    "        return ca, cb\n",
    "\n",
    "    def one_point_crossover_adf_multitask(self, pa, pb):\n",
    "        D = len(pa)\n",
    "        config = self.config\n",
    "        low = config['num_main'] * (config['h_main'] + config['l_main'])\n",
    "        i = np.random.randint(low=low + 1, high=D-1)\n",
    "        low, high = self._get_crossover_range(i)\n",
    "        ca = deepcopy(pa)\n",
    "        cb = deepcopy(pa)\n",
    "        if np.random.rand() < 0.5:\n",
    "            ca[low:i] = pb[low:i]\n",
    "            cb[low:i] = pa[low:i]\n",
    "        else:\n",
    "            ca[i:high] = pb[i:high]\n",
    "            cb[i:high] = pa[i:high]\n",
    "        return ca, cb\n",
    "\n",
    "    def uniform_mutate(self, p, mutation_rate):\n",
    "        c = deepcopy(p)\n",
    "        for i in range(len(p)):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                low, high = self._get_feasible_range(i)\n",
    "                c[i] = np.random.randint(low, high)\n",
    "        return c\n",
    "\n",
    "    def shorten_one_func_of_main(self, p, p_h_main):\n",
    "        c = deepcopy(p)\n",
    "\n",
    "        config = self.config\n",
    "        c_h_main = p_h_main\n",
    "        c_l_main = c_h_main * (config['max_arity'] - 1) + 1\n",
    "\n",
    "        max_sum_arity = config['max_arity'] * c_h_main\n",
    "        R1, R2, R3, R4 = self.chromosome_range\n",
    "\n",
    "        sub_ind = []\n",
    "\n",
    "        not_main_part = c[config['num_main']*(c_h_main+c_l_main):config['dim']]\n",
    "\n",
    "        for i in range(config['num_main']):\n",
    "            sum_arity = 0\n",
    "            sub_tree = c[i*(c_h_main+c_l_main):(i+1)*(c_h_main+c_l_main)]\n",
    "\n",
    "            for j in range(c_h_main):\n",
    "                if sub_tree[j] < R1: sum_arity += FUNCTION_SET[sub_tree[j]][\"arity\"]\n",
    "                else: sum_arity += config[\"max_arity\"]\n",
    "\n",
    "            last_arity = config[\"max_arity\"]\n",
    "            if sub_tree[c_h_main - 1] < R1: last_arity = FUNCTION_SET[sub_tree[c_h_main - 1]][\"arity\"]\n",
    "\n",
    "            head_del = c_h_main - 1\n",
    "            tail_del = c_h_main + c_l_main - (max_sum_arity - sum_arity) - last_arity\n",
    "\n",
    "            sub_tree[head_del] = sub_tree[tail_del]\n",
    "            sub_tree = np.delete(sub_tree, tail_del)\n",
    "\n",
    "            sub_h_main = c_h_main - 1\n",
    "            sub_l_main = sub_h_main * (config['max_arity'] - 1) + 1\n",
    "            sub_tree = sub_tree[:sub_h_main+sub_l_main]\n",
    "\n",
    "            sub_ind.extend(sub_tree)\n",
    "\n",
    "        sub_ind.extend(not_main_part)\n",
    "\n",
    "        return np.array(sub_ind, dtype=np.int32), sub_h_main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atari_benchmark import *\n",
    "from copy import deepcopy\n",
    "from slgep_lib import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.taskset = Taskset(config)\n",
    "        self.cf = []\n",
    "        for h_main in config['h_mains']:\n",
    "            config['h_main'] = h_main\n",
    "            config['h_main_multitask'] = np.max(config['h_mains'])\n",
    "            self.cf.append(ChromosomeFactory(config))\n",
    "\n",
    "    def decode(self, chromosome, sf):\n",
    "        config = self.cf[sf].config\n",
    "        current_h_main = config['h_main_multitask']\n",
    "        while config['h_main'] < current_h_main:\n",
    "            chromosome, _ = self.cf[sf].shorten_one_func_of_main(chromosome, current_h_main)\n",
    "            current_h_main -= 1\n",
    "        return chromosome\n",
    "\n",
    "    def evaluate(self, chromosome, sf):\n",
    "        chromosome = self.decode(chromosome, sf)\n",
    "        self.cf[sf].parse(chromosome)\n",
    "        try:\n",
    "            fitness = self.taskset.run_episode(sf, self.cf[sf].get_action)\n",
    "        except (OverflowError, ValueError) as e:\n",
    "            fitness = np.inf\n",
    "        return fitness\n",
    "\n",
    "\n",
    "class Saver:\n",
    "\n",
    "    def __init__(self, config, instance, seed):\n",
    "        '''Folder result/instance\n",
    "                            config.yaml\n",
    "                            <seed>.pkl\n",
    "        Parameters\n",
    "        ----------\n",
    "            config (dict): configuration of the problem\n",
    "            instance (str): name of the benchmark\n",
    "        '''\n",
    "        self.seed = seed\n",
    "        self.instance = instance\n",
    "        # Create result folder\n",
    "        folder = 'result'\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        folder = 'result/%s' % instance\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        # Save configuration\n",
    "        path = os.path.join(folder, 'config.yaml')\n",
    "        _config = deepcopy(config)\n",
    "        del _config['function_set']\n",
    "        del _config['adf_set']\n",
    "        del _config['adf_terminal_set']\n",
    "        del _config['terminal_set']\n",
    "        with open(path, 'w') as fp:\n",
    "            yaml.dump(_config, fp)\n",
    "        self.results = []\n",
    "\n",
    "    def append(self, result):\n",
    "        self.results.append(result)\n",
    "        self.save()\n",
    "\n",
    "    def save(self):\n",
    "        path = os.path.join('result', self.instance, '%d.pkl' % self.seed)\n",
    "        with open(path, 'wb') as fp:\n",
    "            pickle.dump(self.results, fp, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# MULTIFACTORIAL EVOLUTIONARY HELPER FUNCTIONS\n",
    "def find_relative(population, skill_factor, sf, N):\n",
    "    return population[np.random.choice(np.where(skill_factor[:N] == sf)[0])]\n",
    "\n",
    "\n",
    "def calculate_scalar_fitness(factorial_cost):\n",
    "    return 1 / np.min(np.argsort(np.argsort(factorial_cost, axis=0), axis=0) + 1, axis=1)\n",
    "\n",
    "\n",
    "# OPTIMIZATION RESULT HELPERS\n",
    "def get_best_individual(population, factorial_cost, scalar_fitness, skill_factor, sf):\n",
    "    # select individuals from task sf\n",
    "    idx = np.where(skill_factor == sf)[0]\n",
    "    subpop = population[idx]\n",
    "    sub_factorial_cost = factorial_cost[idx]\n",
    "    sub_scalar_fitness = scalar_fitness[idx]\n",
    "\n",
    "    # select best individual\n",
    "    idx = np.argmax(sub_scalar_fitness)\n",
    "    x = subpop[idx]\n",
    "    fun = sub_factorial_cost[idx, sf]\n",
    "    return x, fun\n",
    "\n",
    "\n",
    "def get_statistics(factorial_cost, skill_factor, sf):\n",
    "    idx = np.where(skill_factor == sf)[0]\n",
    "    sub_factorial_cost = factorial_cost[idx][:, sf]\n",
    "    return np.mean(sub_factorial_cost), np.std(sub_factorial_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quanhm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n",
      "/home/quanhm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = yaml.load(open('config.yaml').read())\n",
    "\n",
    "# Load benchmark\n",
    "singletask_benchmark = yaml.load(open('atari_benchmark/singletask-benchmark.yaml').read())\n",
    "data = singletask_benchmark['single-2']\n",
    "config.update(data)\n",
    "config = wrap_config(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Initializing evaluators\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "taskset = Taskset(config)\n",
    "# Model\n",
    "cf = ChromosomeFactory(config)\n",
    "# Simple parameter\n",
    "K = taskset.K\n",
    "config['K'] = K\n",
    "N = config['pop_size'] * K\n",
    "T = config['num_iter']\n",
    "mutation_rate = config['mutation_rate']\n",
    "# Initialization\n",
    "population = cf.initialize()\n",
    "skill_factor = np.array([i % K for i in range(2 * N)])\n",
    "factorial_cost = np.full([2 * N, K], np.inf)\n",
    "scalar_fitness = np.empty([2 * N])\n",
    "\n",
    "# For parallel evaluation\n",
    "print('[+] Initializing evaluators')\n",
    "evaluators = [Evaluator(config) for _ in range(2 * N)]\n",
    "\n",
    "# First evaluation (sequential)\n",
    "delayed_functions = []\n",
    "for i in range(2 * N):\n",
    "    sf = skill_factor[i]\n",
    "    delayed_functions.append(delayed(evaluators[i].evaluate)(population[i], sf))\n",
    "fitnesses = Parallel(n_jobs=cpu_count())(delayed_functions)\n",
    "for i in range(2 * N):\n",
    "    sf = skill_factor[i]\n",
    "    factorial_cost[i, sf] = fitnesses[i]\n",
    "scalar_fitness = calculate_scalar_fitness(factorial_cost)\n",
    "\n",
    "# Evolve\n",
    "iterator = trange(T)\n",
    "for t in range(10):\n",
    "    # permute current population\n",
    "    permutation_index = np.random.permutation(N)\n",
    "    population[:N] = population[:N][permutation_index]\n",
    "    print('1.',population)\n",
    "    print('1.',population.shape)\n",
    "    skill_factor[:N] = skill_factor[:N][permutation_index]\n",
    "    factorial_cost[:N] = factorial_cost[:N][permutation_index]\n",
    "    factorial_cost[N:] = np.inf\n",
    "\n",
    "    # select pair to crossover\n",
    "    for i in range(0, N, 2):\n",
    "        # extract parent\n",
    "        p1 = population[i]\n",
    "        sf1 = skill_factor[i]\n",
    "        p2 = find_relative(population, skill_factor, sf1, N)\n",
    "        # recombine parent\n",
    "        c1, c2 = cf.one_point_crossover_adf(p1, p2)\n",
    "        c1 = cf.uniform_mutate(c1, mutation_rate)\n",
    "        c2 = cf.uniform_mutate(c2, mutation_rate)\n",
    "        # save child\n",
    "        population[N + i, :], population[N + i + 1, :] = c1[:], c2[:]\n",
    "        skill_factor[N + i] = sf1\n",
    "        skill_factor[N + i + 1] = sf1\n",
    "    # evaluation\n",
    "    delayed_functions = []\n",
    "    for i in range(2 * N):\n",
    "        sf = skill_factor[i]\n",
    "        delayed_functions.append(delayed(evaluators[i].evaluate)(population[i], sf))\n",
    "    fitnesses = Parallel(n_jobs=cpu_count())(delayed_functions)\n",
    "    for i in range(2 * N):\n",
    "        sf = skill_factor[i]\n",
    "        factorial_cost[i, sf] = fitnesses[i]\n",
    "    scalar_fitness = calculate_scalar_fitness(factorial_cost)\n",
    "\n",
    "    # sort\n",
    "    sort_index = np.argsort(scalar_fitness)[::-1]\n",
    "    population = population[sort_index]\n",
    "    print('2.',population)\n",
    "    print('2.',population.shape)\n",
    "    skill_factor = skill_factor[sort_index]\n",
    "    factorial_cost = factorial_cost[sort_index]\n",
    "    scalar_fitness = scalar_fitness[sort_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromosomeRange(R1=6, R2=14, R3=16, R4=144)\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "taskset = Taskset(config)\n",
    "# Model\n",
    "cf = ChromosomeFactory(config)\n",
    "# Simple parameter\n",
    "K = taskset.K\n",
    "config['K'] = K\n",
    "N = config['pop_size'] * K\n",
    "T = config['num_iter']\n",
    "mutation_rate = config['mutation_rate']\n",
    "# Initialization\n",
    "population = cf.initialize()\n",
    "print(cf.chromosome_range)\n",
    "nos = population.shape[0]\n",
    "for i in range(nos):  # Leave-one-out cross validation scheme\n",
    "    x = np.append(population[:i, :], population[i + 1:, :], 0)\n",
    "    tmodel = ProbabilityModel('mvarnorm')\n",
    "    tmodel.buildmodel(x)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 2 5 0 1 6 3 7 9]\n"
     ]
    }
   ],
   "source": [
    "permutation_index = np.random.permutation(10)\n",
    "print(permutation_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  8 ... 14 14 15]\n",
      " [ 9  8  9 ... 14 15 14]\n",
      " [ 2  6  8 ... 14 14 14]\n",
      " ...\n",
      " [ 9 12  5 ... 14 14 14]\n",
      " [ 6  1  5 ... 14 14 14]\n",
      " [11 12  4 ... 14 15 14]]\n",
      "(20, 108)\n"
     ]
    }
   ],
   "source": [
    "population[:10] = population[:10][permutation_index]\n",
    "print(population)\n",
    "print(population.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 108)\n"
     ]
    }
   ],
   "source": [
    "covariance = np.cov(population.T)\n",
    "print(covariance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 108)\n"
     ]
    }
   ],
   "source": [
    "covarmat_true = np.diag(np.diag(covariance))\n",
    "print(covarmat_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 108), (108,), (108, 108))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(population, axis=0)\n",
    "population.shape, mean.shape, covarmat_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covarmat_true[100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.81369506e-125, 4.41986562e-123, 5.30403398e-120, 1.80457011e-124,\n",
       "        2.70082114e-119, 2.20562926e-122, 3.13500363e-122, 9.84538409e-121,\n",
       "        1.98389102e-123, 9.59908932e-125, 3.17202993e-120, 3.41729668e-124,\n",
       "        1.40453321e-124, 1.23472228e-123, 1.09803900e-127, 5.98384925e-124,\n",
       "        6.64505061e-125, 2.90967299e-124, 3.25178003e-123, 2.33148294e-124]),\n",
       " (20,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population2 = cf.initialize()\n",
    "mvn = multivariate_normal.pdf(population2, mean, covarmat_true, allow_singular = True)\n",
    "mvn, mvn.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.58000000e+01, 1.36289474e+01, 1.17263158e+01, 1.76947368e+01,\n",
       "       1.15684211e+01, 1.98815789e+01, 1.74708158e+03, 1.76920000e+03,\n",
       "       1.62536842e+03, 8.88765789e+02, 1.00595789e+03, 1.26087105e+03,\n",
       "       1.43106316e+03, 1.38815789e+01, 1.36289474e+01, 2.04500000e+01,\n",
       "       1.51026316e+01, 1.71052632e+01, 1.84736842e+01, 1.78827368e+03,\n",
       "       8.66576316e+02, 1.16946316e+03, 1.11983947e+03, 1.42573421e+03,\n",
       "       1.46478947e+03, 2.02866053e+03, 1.94631579e+01, 1.18184211e+01,\n",
       "       1.29763158e+01, 1.24710526e+01, 1.33263158e+01, 2.02394737e+01,\n",
       "       9.80513158e+02, 1.30101053e+03, 6.32576316e+02, 7.76765789e+02,\n",
       "       1.33466053e+03, 1.35674737e+03, 1.17546316e+03, 2.42105263e+01,\n",
       "       1.09368421e+01, 1.52526316e+01, 1.71578947e+01, 1.43263158e+01,\n",
       "       1.41973684e+01, 1.56693684e+03, 9.92431579e+02, 9.95944737e+02,\n",
       "       1.45651579e+03, 1.01925000e+03, 1.26630263e+03, 1.07204211e+03,\n",
       "       3.31315789e+00, 1.62894737e+00, 2.76578947e+00, 2.39473684e-01,\n",
       "       2.60526316e-01, 2.21052632e-01, 1.68421053e-01, 2.48421053e+00,\n",
       "       3.26315789e+00, 2.66052632e+00, 2.52631579e-01, 2.60526316e-01,\n",
       "       2.21052632e-01, 2.60526316e-01, 2.55526316e+00, 3.41842105e+00,\n",
       "       2.40789474e+00, 2.52631579e-01, 1.97368421e-01, 2.52631579e-01,\n",
       "       2.60526316e-01, 3.52368421e+00, 3.32631579e+00, 3.72631579e+00,\n",
       "       2.60526316e-01, 2.60526316e-01, 2.52631579e-01, 2.52631579e-01,\n",
       "       3.69473684e+00, 1.93684211e+00, 3.46052632e+00, 2.63157895e-01,\n",
       "       2.52631579e-01, 2.63157895e-01, 2.60526316e-01, 1.63157895e+00,\n",
       "       2.99736842e+00, 3.31578947e+00, 2.52631579e-01, 2.60526316e-01,\n",
       "       2.60526316e-01, 2.21052632e-01, 2.68157895e+00, 3.18684211e+00,\n",
       "       2.16842105e+00, 2.63157895e-01, 2.39473684e-01, 2.60526316e-01,\n",
       "       2.63157895e-01, 2.64210526e+00, 1.85263158e+00, 3.10263158e+00,\n",
       "       2.39473684e-01, 2.60526316e-01, 2.60526316e-01, 2.21052632e-01])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01058315,  0.02262643, -0.01066715,  0.00271562])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0, 0.01, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 2, 1, 9, 8, 4, 3, 7, 6])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round([0.2,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193456206299983"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multivariate_normal([2,3], [[3,3],[3,3]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float64' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-152eb64f2023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.742e-1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'float64' is not defined"
     ]
    }
   ],
   "source": [
    "np.array([1.742e-1]).astype(float64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
