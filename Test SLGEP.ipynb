{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "class ProbabilityModel:  # Works reliably for 2(+) Dimensional distributions\n",
    "    \"\"\" properties\n",
    "        modeltype; % multivariate normal ('mvarnorm' - for real coded) or univariate marginal distribution ('umd' - for binary coded)    \n",
    "        mean_noisy;\n",
    "        mean_true;\n",
    "        covarmat_noisy;\n",
    "        covarmat_true;\n",
    "        probofone_noisy;\n",
    "        probofone_true;\n",
    "        probofzero_noisy;\n",
    "        probofzero_true;    \n",
    "        vars;\n",
    "      end\"\"\"\n",
    "\n",
    "\n",
    "    def sample(self, nos):\n",
    "        # print('nos,self.vars', nos,self.vars)\n",
    "        nos = int(nos)\n",
    "        solutions = np.random.multivariate_normal(self.mean_true, self.covarmat_true, size=nos)\n",
    "        return solutions\n",
    "\n",
    "    def pdfeval(self, solutions):\n",
    "        \"\"\"Calculating the probabilty of every solution\n",
    "        \n",
    "        Arguments:\n",
    "            solutions {[2-D Array]} -- [solution or population of evolutionary algorithm]\n",
    "        \n",
    "        Returns:\n",
    "            [1-D Array] -- [probabilty of every solution]\n",
    "        \"\"\"\n",
    "\n",
    "        mvn = multivariate_normal(self.mean_noisy,self.covarmat_noisy)  \n",
    "        # create a multivariate Gaussian object with specified mean and covariance matrix\n",
    "        probofsols = mvn.pdf(solutions)\n",
    "        return probofsols\n",
    "\n",
    "    def buildmodel(self, solutions):\n",
    "        pop, self.vars = solutions.shape\n",
    "        self.mean_true = np.mean(solutions, 0)\n",
    "        # Tính ma trận hiệp phương sai của solutions. Ma trận hiệp phương sai có đường chéo chính là phương sai\n",
    "        # của các mẫu dữ liệu theo từng chiều\n",
    "        covariance = np.cov(solutions)\n",
    "        # Simplifying to univariate distribution by ignoring off diagonal terms of covariance matrix\n",
    "        # Giữ lại đường chéo chính của ma trận hiệp phương sai\n",
    "        self.covarmat_true = np.diag(np.diag(covariance))\n",
    "        # Thêm 10% noise để tránh overfit\n",
    "        solutions_noisy = np.append(solutions, np.random.rand(round(0.1 * pop), self.vars), 0)\n",
    "        self.mean_noisy = np.mean(solutions_noisy, 0)\n",
    "        covariance = np.cov(solutions_noisy)\n",
    "        # Simplifying to univariate distribution by ignoring off diagonal terms of covariance matrix\n",
    "        self.covarmat_noisy = np.diag(np.diag(covariance))\n",
    "        self.covarmat_noisy = np.cov(solutions_noisy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from slgep_lib import wrap_config\n",
    "from utils import Saver\n",
    "from cea import cea\n",
    "import argparse\n",
    "import yaml\n",
    "from tools import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Taskset:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        names = config['names']\n",
    "        self.config = config\n",
    "        self.envs = [gym.make(name) for name in names]\n",
    "\n",
    "    def run_episode(self, sf, policy_function):\n",
    "        env = self.envs[0]\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "        for i in range(18000):\n",
    "            action = policy_function(observation.astype(np.float32))\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return -total_reward\n",
    "\n",
    "    @property\n",
    "    def K(self):\n",
    "        return len(self.config['h_mains'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import namedtuple\n",
    "\n",
    "ChromosomeRange = namedtuple('ChromosomeRange', ('R1', 'R2', 'R3', 'R4'))\n",
    "# | --- Function Set --- | --- ADF Set --- | --- ADF Terminal Set --- | --- Terminals --- |\n",
    "# | 'function_set'       | 'adf_set'       | 'adf_terminal_set'       | 'terminal_set'    |\n",
    "# |                      |                 |        (Variables)       |     (Inputs)      |\n",
    "# 0 ---------------------| R1 -------------| R2 ----------------------| R3 ---------------| R4\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, index, arity, parent, chromosome_factory):\n",
    "        self.index = index\n",
    "        self.arity = arity\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.chromosome_factory = chromosome_factory\n",
    "\n",
    "    def _set_adfs_terminals(self, inputs):\n",
    "        config = self.chromosome_factory.config\n",
    "        for i in range(len(config['adf_terminal_set'])):\n",
    "            config['adf_terminal_set'][i]['value'] = inputs[i]\n",
    "\n",
    "    def get_value(self):\n",
    "        config = self.chromosome_factory.config\n",
    "        # Extract range\n",
    "        R1, R2, R3, R4 = self.chromosome_factory.chromosome_range\n",
    "        # If this node is a leaf, return its value\n",
    "        if self.index >= R3:\n",
    "            return config['terminal_set'][self.index - R3]['value']\n",
    "        if self.index >= R2:\n",
    "            return config['adf_terminal_set'][self.index - R2]['value']\n",
    "        # If this node is a function or ADF node, \n",
    "        # we need to pass in its children as params\n",
    "        params = []\n",
    "        for child in self.children:\n",
    "            value = child.get_value()\n",
    "            if np.isnan(value):\n",
    "                return float('nan')\n",
    "            params.append(child.get_value())\n",
    "        # If this node is an auto defined function\n",
    "        # Assign input to the ADF variables\n",
    "        if self.index >= R1:\n",
    "            self._set_adfs_terminals(params)\n",
    "            return config['adf_set'][self.index - R1]['func'].get_value()\n",
    "        # If this node is a normal function\n",
    "        function = config['function_set'][self.index]\n",
    "        return config['function_set'][self.index]['func'](*params)\n",
    "\n",
    "class ADF:\n",
    "\n",
    "    def __init__(self, gene, chromosome_factory):\n",
    "        self.gene = gene\n",
    "        self.root = None\n",
    "        self.chromosome_factory = chromosome_factory\n",
    "        self._parse()\n",
    "\n",
    "    def _parse(self):\n",
    "        config = self.chromosome_factory.config\n",
    "        symbols = config['function_set'] + config['adf_set'] + \\\n",
    "                  config['terminal_set'] + config['adf_terminal_set']\n",
    "\n",
    "        gene = deepcopy(self.gene).tolist()\n",
    "\n",
    "        # Assign root\n",
    "        self.root = Node(index=gene[0],\n",
    "                         arity=symbols[gene[0]]['arity'],\n",
    "                         parent=None,\n",
    "                         chromosome_factory=self.chromosome_factory)\n",
    "        queue = [self.root]\n",
    "        gene.pop(0)\n",
    "\n",
    "        # Traverse BFS to build tree\n",
    "        while len(queue) and len(gene):\n",
    "            parent = queue.pop(0)\n",
    "\n",
    "            for i in range(parent.arity):\n",
    "                node = Node(index=gene[0],\n",
    "                            arity=symbols[gene[0]]['arity'],\n",
    "                            parent=parent,\n",
    "                            chromosome_factory=self.chromosome_factory)\n",
    "                queue.append(node)\n",
    "                gene.pop(0)\n",
    "                parent.children.append(node)\n",
    "\n",
    "    def get_value(self):\n",
    "        return self.root.get_value()\n",
    "\n",
    "class ChromosomeFactory:\n",
    "\n",
    "    def __init__(self, _config):\n",
    "        self.config = _config\n",
    "        # Assign defined structure of the solution\n",
    "        config = _config\n",
    "        # Compute chromosome range\n",
    "        R1 = len(config['function_set'])\n",
    "        R2 = R1 + len(config['adf_set'])\n",
    "        R3 = R2 + len(config['adf_terminal_set'])\n",
    "        R4 = R3 + len(config['terminal_set'])\n",
    "        self.chromosome_range = ChromosomeRange(R1, R2, R3, R4)\n",
    "\n",
    "    def _get_feasible_range(self, i):\n",
    "        R1, R2, R3, R4 = self.chromosome_range\n",
    "        config = self.config\n",
    "        # gene at i belong to one of the given mains\n",
    "        if i < config['num_main'] * (config['h_main'] + config['l_main']):\n",
    "            if i % (config['h_main'] + config['l_main']) < config['h_main']:\n",
    "                # Head of main: adf_set and function_set\n",
    "                return 0, R2\n",
    "            else:\n",
    "                # Tail of main: terminal_set\n",
    "                return R3, R4\n",
    "        if (i - config['num_main'] * (config['h_main'] + config['l_main'])) % \\\n",
    "                (config['h_adf'] + config['l_adf']) < config['h_adf']:\n",
    "            # Head of ADF: function_set\n",
    "            return 0, R1\n",
    "        else:\n",
    "            # Tail of ADF: adf_terminal_set\n",
    "            return R2, R3\n",
    "\n",
    "    def initialize(self):\n",
    "        config = self.config\n",
    "        population = np.empty([config['pop_size'] * config['K'] * 2, config['dim']])\n",
    "        for j in range(config['dim']):\n",
    "            low, high = self._get_feasible_range(j)\n",
    "            population[:, j] = np.random.randint(low, high, size=config['pop_size'] * config['K'] * 2)\n",
    "        return population.astype(np.int32)\n",
    "\n",
    "    def parse(self, chromosome):\n",
    "        # Parse the auto defined functions\n",
    "        config = self.config\n",
    "        for i in range(config['num_adf']):\n",
    "            head = config['num_main'] * (config['h_main'] + config['l_main']) + \\\n",
    "                   i * (config['h_adf'] + config['l_adf'])\n",
    "            tail = head + config['h_adf'] + config['l_adf']\n",
    "            config['adf_set'][i]['func'] = ADF(chromosome[head:tail], self)\n",
    "\n",
    "        # Parse the main program\n",
    "        for i in range(config['num_main']):\n",
    "            head = i * (config['h_main'] + config['l_main'])\n",
    "            tail = head + config['h_main'] + config['l_main']\n",
    "            config['main'].append(ADF(chromosome[head:tail], self))\n",
    "\n",
    "    def _set_main_terminals(self, inputs):\n",
    "        config = self.config\n",
    "        for i in range(len(config['terminal_set'])):\n",
    "            config['terminal_set'][i]['value'] = inputs[i]\n",
    "\n",
    "    def get_value(self, inputs):\n",
    "        config = self.config\n",
    "        self._set_main_terminals(inputs)\n",
    "        outputs = []\n",
    "        for i in range(config['num_main']):\n",
    "            outputs.append(config['main'][i].get_value())\n",
    "        return outputs\n",
    "\n",
    "    def get_action(self, inputs):\n",
    "        config = self.config\n",
    "        self._set_main_terminals(inputs)\n",
    "        outputs = []\n",
    "        for i in range(config['num_main']):\n",
    "            outputs.append(config['main'][i].get_value())\n",
    "        outputs = np.array(outputs)\n",
    "        outputs[np.where(outputs == np.nan)[0]] = -np.inf\n",
    "        return np.argmax(outputs)\n",
    "\n",
    "    def one_point_crossover(self, pa, pb):\n",
    "        D = len(pa)\n",
    "        index = np.random.randint(low=1, high=D-1)\n",
    "        ca = np.empty_like(pa)\n",
    "        cb = np.empty_like(pa)\n",
    "\n",
    "        ca = np.concatenate([pa[:index], pb[index:]])\n",
    "        cb = np.concatenate([pb[:index], pb[index:]])\n",
    "        return ca, cb\n",
    "\n",
    "    def _get_crossover_range(self, i):\n",
    "        config = self.config\n",
    "        n, h, l = config['num_main'], config['h_main'], config['l_main']\n",
    "        n_adf, h_adf, l_adf = config['num_adf'], config['h_adf'], config['l_adf']\n",
    "        if i < n * (h + l):\n",
    "            if i % (l + h) == 0:\n",
    "                low = (i / (h + l) - 1) * (h + l)\n",
    "                high = (i / (h + l) + 1) * (h + l)\n",
    "            else:\n",
    "                low = np.floor(i / (h + l)) * (h + l)\n",
    "                high = np.ceil(i / (h + l)) * (h + l)\n",
    "        else:\n",
    "            j = i - n * (h + l)\n",
    "            if j % (l_adf + h_adf) == 0:\n",
    "                low = (j / (h_adf + l_adf) - 1) * (h_adf + l_adf)\n",
    "                high = (j / (h_adf + l_adf) + 1) * (h_adf + l_adf)\n",
    "            else:\n",
    "                low = np.floor(j / (h_adf + l_adf)) * (h_adf + l_adf)\n",
    "                high = np.ceil(j / (h_adf + l_adf)) * (h_adf + l_adf)\n",
    "            low += n * (h + l)\n",
    "            high += n * (h + l)\n",
    "        return int(low), int(high)\n",
    "\n",
    "    def one_point_crossover_adf(self, pa, pb):\n",
    "        D = len(pa)\n",
    "        i = np.random.randint(low=1, high=D-1)\n",
    "        low, high = self._get_crossover_range(i)\n",
    "        ca = deepcopy(pa)\n",
    "        cb = deepcopy(pa)\n",
    "        if np.random.rand() < 0.5:\n",
    "            ca[low:i] = pb[low:i]\n",
    "            cb[low:i] = pa[low:i]\n",
    "        else:\n",
    "            ca[i:high] = pb[i:high]\n",
    "            cb[i:high] = pa[i:high]\n",
    "        return ca, cb\n",
    "\n",
    "    def one_point_crossover_adf_multitask(self, pa, pb):\n",
    "        D = len(pa)\n",
    "        config = self.config\n",
    "        low = config['num_main'] * (config['h_main'] + config['l_main'])\n",
    "        i = np.random.randint(low=low + 1, high=D-1)\n",
    "        low, high = self._get_crossover_range(i)\n",
    "        ca = deepcopy(pa)\n",
    "        cb = deepcopy(pa)\n",
    "        if np.random.rand() < 0.5:\n",
    "            ca[low:i] = pb[low:i]\n",
    "            cb[low:i] = pa[low:i]\n",
    "        else:\n",
    "            ca[i:high] = pb[i:high]\n",
    "            cb[i:high] = pa[i:high]\n",
    "        return ca, cb\n",
    "\n",
    "    def uniform_mutate(self, p, mutation_rate):\n",
    "        c = deepcopy(p)\n",
    "        for i in range(len(p)):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                low, high = self._get_feasible_range(i)\n",
    "                c[i] = np.random.randint(low, high)\n",
    "        return c\n",
    "\n",
    "    def shorten_one_func_of_main(self, p, p_h_main):\n",
    "        c = deepcopy(p)\n",
    "\n",
    "        config = self.config\n",
    "        c_h_main = p_h_main\n",
    "        c_l_main = c_h_main * (config['max_arity'] - 1) + 1\n",
    "\n",
    "        max_sum_arity = config['max_arity'] * c_h_main\n",
    "        R1, R2, R3, R4 = self.chromosome_range\n",
    "\n",
    "        sub_ind = []\n",
    "\n",
    "        not_main_part = c[config['num_main']*(c_h_main+c_l_main):config['dim']]\n",
    "\n",
    "        for i in range(config['num_main']):\n",
    "            sum_arity = 0\n",
    "            sub_tree = c[i*(c_h_main+c_l_main):(i+1)*(c_h_main+c_l_main)]\n",
    "\n",
    "            for j in range(c_h_main):\n",
    "                if sub_tree[j] < R1: sum_arity += FUNCTION_SET[sub_tree[j]][\"arity\"]\n",
    "                else: sum_arity += config[\"max_arity\"]\n",
    "\n",
    "            last_arity = config[\"max_arity\"]\n",
    "            if sub_tree[c_h_main - 1] < R1: last_arity = FUNCTION_SET[sub_tree[c_h_main - 1]][\"arity\"]\n",
    "\n",
    "            head_del = c_h_main - 1\n",
    "            tail_del = c_h_main + c_l_main - (max_sum_arity - sum_arity) - last_arity\n",
    "\n",
    "            sub_tree[head_del] = sub_tree[tail_del]\n",
    "            sub_tree = np.delete(sub_tree, tail_del)\n",
    "\n",
    "            sub_h_main = c_h_main - 1\n",
    "            sub_l_main = sub_h_main * (config['max_arity'] - 1) + 1\n",
    "            sub_tree = sub_tree[:sub_h_main+sub_l_main]\n",
    "\n",
    "            sub_ind.extend(sub_tree)\n",
    "\n",
    "        sub_ind.extend(not_main_part)\n",
    "\n",
    "        return np.array(sub_ind, dtype=np.int32), sub_h_main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atari_benchmark import *\n",
    "from copy import deepcopy\n",
    "from slgep_lib import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.taskset = Taskset(config)\n",
    "        self.cf = []\n",
    "        for h_main in config['h_mains']:\n",
    "            config['h_main'] = h_main\n",
    "            config['h_main_multitask'] = np.max(config['h_mains'])\n",
    "            self.cf.append(ChromosomeFactory(config))\n",
    "\n",
    "    def decode(self, chromosome, sf):\n",
    "        config = self.cf[sf].config\n",
    "        current_h_main = config['h_main_multitask']\n",
    "        while config['h_main'] < current_h_main:\n",
    "            chromosome, _ = self.cf[sf].shorten_one_func_of_main(chromosome, current_h_main)\n",
    "            current_h_main -= 1\n",
    "        return chromosome\n",
    "\n",
    "    def evaluate(self, chromosome, sf):\n",
    "        chromosome = self.decode(chromosome, sf)\n",
    "        self.cf[sf].parse(chromosome)\n",
    "        try:\n",
    "            fitness = self.taskset.run_episode(sf, self.cf[sf].get_action)\n",
    "        except (OverflowError, ValueError) as e:\n",
    "            fitness = np.inf\n",
    "        return fitness\n",
    "\n",
    "\n",
    "class Saver:\n",
    "\n",
    "    def __init__(self, config, instance, seed):\n",
    "        '''Folder result/instance\n",
    "                            config.yaml\n",
    "                            <seed>.pkl\n",
    "        Parameters\n",
    "        ----------\n",
    "            config (dict): configuration of the problem\n",
    "            instance (str): name of the benchmark\n",
    "        '''\n",
    "        self.seed = seed\n",
    "        self.instance = instance\n",
    "        # Create result folder\n",
    "        folder = 'result'\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        folder = 'result/%s' % instance\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        # Save configuration\n",
    "        path = os.path.join(folder, 'config.yaml')\n",
    "        _config = deepcopy(config)\n",
    "        del _config['function_set']\n",
    "        del _config['adf_set']\n",
    "        del _config['adf_terminal_set']\n",
    "        del _config['terminal_set']\n",
    "        with open(path, 'w') as fp:\n",
    "            yaml.dump(_config, fp)\n",
    "        self.results = []\n",
    "\n",
    "    def append(self, result):\n",
    "        self.results.append(result)\n",
    "        self.save()\n",
    "\n",
    "    def save(self):\n",
    "        path = os.path.join('result', self.instance, '%d.pkl' % self.seed)\n",
    "        with open(path, 'wb') as fp:\n",
    "            pickle.dump(self.results, fp, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# MULTIFACTORIAL EVOLUTIONARY HELPER FUNCTIONS\n",
    "def find_relative(population, skill_factor, sf, N):\n",
    "    return population[np.random.choice(np.where(skill_factor[:N] == sf)[0])]\n",
    "\n",
    "\n",
    "def calculate_scalar_fitness(factorial_cost):\n",
    "    return 1 / np.min(np.argsort(np.argsort(factorial_cost, axis=0), axis=0) + 1, axis=1)\n",
    "\n",
    "\n",
    "# OPTIMIZATION RESULT HELPERS\n",
    "def get_best_individual(population, factorial_cost, scalar_fitness, skill_factor, sf):\n",
    "    # select individuals from task sf\n",
    "    idx = np.where(skill_factor == sf)[0]\n",
    "    subpop = population[idx]\n",
    "    sub_factorial_cost = factorial_cost[idx]\n",
    "    sub_scalar_fitness = scalar_fitness[idx]\n",
    "\n",
    "    # select best individual\n",
    "    idx = np.argmax(sub_scalar_fitness)\n",
    "    x = subpop[idx]\n",
    "    fun = sub_factorial_cost[idx, sf]\n",
    "    return x, fun\n",
    "\n",
    "\n",
    "def get_statistics(factorial_cost, skill_factor, sf):\n",
    "    idx = np.where(skill_factor == sf)[0]\n",
    "    sub_factorial_cost = factorial_cost[idx][:, sf]\n",
    "    return np.mean(sub_factorial_cost), np.std(sub_factorial_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quanhm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n",
      "/home/quanhm/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = yaml.load(open('config.yaml').read())\n",
    "\n",
    "# Load benchmark\n",
    "singletask_benchmark = yaml.load(open('atari_benchmark/singletask-benchmark.yaml').read())\n",
    "data = singletask_benchmark['single-2']\n",
    "config.update(data)\n",
    "config = wrap_config(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Initializing evaluators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [[ 5  5 12 ... 15 14 14]\n",
      " [ 7 13  9 ... 15 14 15]\n",
      " [ 2  9  3 ... 14 14 14]\n",
      " ...\n",
      " [ 5 11  2 ... 14 14 14]\n",
      " [ 7 11  4 ... 15 15 15]\n",
      " [ 9 12  9 ... 15 14 14]]\n",
      "1. (20, 108)\n",
      "2. [[ 5  5 12 ... 15 14 14]\n",
      " [10 11 10 ... 14 14 15]\n",
      " [10 11 10 ... 14 14 15]\n",
      " ...\n",
      " [ 7 13  9 ... 15 14 15]\n",
      " [13  7  3 ... 14 14 14]\n",
      " [13  7  3 ... 14 14 15]]\n",
      "2. (20, 108)\n",
      "1. [[ 8 10  1 ... 14 15 14]\n",
      " [ 2  9  3 ... 14 14 14]\n",
      " [10  9  3 ... 14 14 14]\n",
      " ...\n",
      " [ 7 13  9 ... 15 14 15]\n",
      " [13  7  3 ... 14 14 14]\n",
      " [13  7  3 ... 14 14 15]]\n",
      "1. (20, 108)\n",
      "2. [[ 8 10  1 ... 14 15 14]\n",
      " [ 5  5 12 ... 15 14 14]\n",
      " [ 5  5 12 ... 15 14 14]\n",
      " ...\n",
      " [ 2  9  3 ... 14 14 14]\n",
      " [ 5  5 12 ... 15 14 14]\n",
      " [ 5  5 12 ... 15 14 14]]\n",
      "2. (20, 108)\n",
      "1. [[ 8 10  1 ... 14 15 14]\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [10  9  1 ... 14 14 14]\n",
      " ...\n",
      " [ 2  9  3 ... 14 14 14]\n",
      " [ 5  5 12 ... 15 14 14]\n",
      " [ 5  5 12 ... 15 14 14]]\n",
      "1. (20, 108)\n",
      "2. [[ 8 10  1 ... 14 15 14]\n",
      " [ 5  5 12 ... 15 14 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " ...\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [10 11 10 ... 14 14 15]\n",
      " [10 11 10 ... 14 14 15]]\n",
      "2. (20, 108)\n",
      "1. [[ 8 10  1 ... 14 15 14]\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [10  9  1 ... 14 14 15]\n",
      " ...\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [10 11 10 ... 14 14 15]\n",
      " [10 11 10 ... 14 14 15]]\n",
      "1. (20, 108)\n",
      "2. [[ 8 10  1 ... 14 15 14]\n",
      " [10  9  1 ... 14 14 14]\n",
      " [10  9  1 ... 14 14 14]\n",
      " ...\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [ 8 10  1 ... 14 15 14]]\n",
      "2. (20, 108)\n",
      "1. [[12  5 12 ... 15 14 14]\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [10  9  1 ... 14 14 14]\n",
      " ...\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [ 8 10  1 ... 14 15 14]]\n",
      "1. (20, 108)\n",
      "2. [[12  5 12 ... 15 14 14]\n",
      " [10  9  1 ... 14 14 15]\n",
      " [10  9  4 ... 14 14 15]\n",
      " ...\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [10  9  1 ... 14 14 14]\n",
      " [ 4  9  1 ... 14 14 15]]\n",
      "2. (20, 108)\n",
      "1. [[12 10 12 ... 15 14 14]\n",
      " [ 8  0  1 ... 14 15 14]\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " ...\n",
      " [ 8 10  1 ... 14 15 14]\n",
      " [10  9  1 ... 14 14 14]\n",
      " [ 4  9  1 ... 14 14 15]]\n",
      "1. (20, 108)\n",
      "2. [[12 10 12 ... 15 14 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " ...\n",
      " [ 8  0  1 ... 14 15 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " [12  4 12 ... 15 14 14]]\n",
      "2. (20, 108)\n",
      "1. [[12 10 12 ... 15 14 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " [ 8 13  1 ... 14 15 14]\n",
      " ...\n",
      " [ 8  0  1 ... 14 15 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " [12  4 12 ... 15 14 14]]\n",
      "1. (20, 108)\n",
      "2. [[12 10 12 ... 15 14 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " ...\n",
      " [12  5 12 ... 15 14 14]\n",
      " [ 1 10  1 ... 14 15 14]\n",
      " [ 1 10  1 ... 14 15 14]]\n",
      "2. (20, 108)\n",
      "1. [[12 10 12 ... 15 14 14]\n",
      " [12  5 12 ... 15 14 14]\n",
      " [ 8 13  1 ... 14 15 14]\n",
      " ...\n",
      " [12  5 12 ... 15 14 14]\n",
      " [ 1 10  1 ... 14 15 14]\n",
      " [ 1 10  1 ... 14 15 14]]\n",
      "1. (20, 108)\n",
      "2. [[12 10 12 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]\n",
      " ...\n",
      " [12  5 12 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]]\n",
      "2. (20, 108)\n",
      "1. [[12 10  6 ... 15 14 14]\n",
      " [12 10 12 ... 15 14 14]\n",
      " [ 8 13  1 ... 14 15 14]\n",
      " ...\n",
      " [12  5 12 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]]\n",
      "1. (20, 108)\n",
      "2. [[ 8 13  1 ... 14 15 14]\n",
      " [12 10  6 ... 15 14 14]\n",
      " [12 10 12 ... 15 14 14]\n",
      " ...\n",
      " [12 10 12 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]]\n",
      "2. (20, 108)\n",
      "1. [[ 8 13  1 ... 14 15 14]\n",
      " [12 10 12 ... 15 14 14]\n",
      " [12 10 12 ... 15 14 14]\n",
      " ...\n",
      " [12 10 12 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]\n",
      " [12 10  6 ... 15 14 14]]\n",
      "1. (20, 108)\n",
      "2. [[ 8 13  1 ... 14 15 14]\n",
      " [ 8 13  1 ... 14 15 14]\n",
      " [ 8 13  1 ... 14 15 14]\n",
      " ...\n",
      " [12 10 12 ... 15 14 14]\n",
      " [ 8 13  1 ... 14 15 14]\n",
      " [ 8 13  1 ... 14 15 14]]\n",
      "2. (20, 108)\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "taskset = Taskset(config)\n",
    "# Model\n",
    "cf = ChromosomeFactory(config)\n",
    "# Simple parameter\n",
    "K = taskset.K\n",
    "config['K'] = K\n",
    "N = config['pop_size'] * K\n",
    "T = config['num_iter']\n",
    "mutation_rate = config['mutation_rate']\n",
    "# Initialization\n",
    "population = cf.initialize()\n",
    "skill_factor = np.array([i % K for i in range(2 * N)])\n",
    "factorial_cost = np.full([2 * N, K], np.inf)\n",
    "scalar_fitness = np.empty([2 * N])\n",
    "\n",
    "# For parallel evaluation\n",
    "print('[+] Initializing evaluators')\n",
    "evaluators = [Evaluator(config) for _ in range(2 * N)]\n",
    "\n",
    "# First evaluation (sequential)\n",
    "delayed_functions = []\n",
    "for i in range(2 * N):\n",
    "    sf = skill_factor[i]\n",
    "    delayed_functions.append(delayed(evaluators[i].evaluate)(population[i], sf))\n",
    "fitnesses = Parallel(n_jobs=cpu_count())(delayed_functions)\n",
    "for i in range(2 * N):\n",
    "    sf = skill_factor[i]\n",
    "    factorial_cost[i, sf] = fitnesses[i]\n",
    "scalar_fitness = calculate_scalar_fitness(factorial_cost)\n",
    "\n",
    "# Evolve\n",
    "iterator = trange(T)\n",
    "for t in range(10):\n",
    "    # permute current population\n",
    "    permutation_index = np.random.permutation(N)\n",
    "    population[:N] = population[:N][permutation_index]\n",
    "    print('1.',population)\n",
    "    print('1.',population.shape)\n",
    "    skill_factor[:N] = skill_factor[:N][permutation_index]\n",
    "    factorial_cost[:N] = factorial_cost[:N][permutation_index]\n",
    "    factorial_cost[N:] = np.inf\n",
    "\n",
    "    # select pair to crossover\n",
    "    for i in range(0, N, 2):\n",
    "        # extract parent\n",
    "        p1 = population[i]\n",
    "        sf1 = skill_factor[i]\n",
    "        p2 = find_relative(population, skill_factor, sf1, N)\n",
    "        # recombine parent\n",
    "        c1, c2 = cf.one_point_crossover_adf(p1, p2)\n",
    "        c1 = cf.uniform_mutate(c1, mutation_rate)\n",
    "        c2 = cf.uniform_mutate(c2, mutation_rate)\n",
    "        # save child\n",
    "        population[N + i, :], population[N + i + 1, :] = c1[:], c2[:]\n",
    "        skill_factor[N + i] = sf1\n",
    "        skill_factor[N + i + 1] = sf1\n",
    "    # evaluation\n",
    "    delayed_functions = []\n",
    "    for i in range(2 * N):\n",
    "        sf = skill_factor[i]\n",
    "        delayed_functions.append(delayed(evaluators[i].evaluate)(population[i], sf))\n",
    "    fitnesses = Parallel(n_jobs=cpu_count())(delayed_functions)\n",
    "    for i in range(2 * N):\n",
    "        sf = skill_factor[i]\n",
    "        factorial_cost[i, sf] = fitnesses[i]\n",
    "    scalar_fitness = calculate_scalar_fitness(factorial_cost)\n",
    "\n",
    "    # sort\n",
    "    sort_index = np.argsort(scalar_fitness)[::-1]\n",
    "    population = population[sort_index]\n",
    "    print('2.',population)\n",
    "    print('2.',population.shape)\n",
    "    skill_factor = skill_factor[sort_index]\n",
    "    factorial_cost = factorial_cost[sort_index]\n",
    "    scalar_fitness = scalar_fitness[sort_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  3  7 ... 15 14 14]\n",
      " [11  2  3 ... 15 15 15]\n",
      " [ 3 10  3 ... 14 14 15]\n",
      " ...\n",
      " [ 0 12 11 ... 14 14 15]\n",
      " [ 8  6 11 ... 14 15 15]\n",
      " [12  0 11 ... 15 14 14]]\n",
      "(20, 108)\n"
     ]
    }
   ],
   "source": [
    "cf = ChromosomeFactory(config)\n",
    "population = cf.initialize()\n",
    "print(population)\n",
    "print(population.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 0 9 6 2 8 7 1 3]\n"
     ]
    }
   ],
   "source": [
    "permutation_index = np.random.permutation(10)\n",
    "print(permutation_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  4  5 ... 14 15 14]\n",
      " [ 6  2 10 ... 15 14 15]\n",
      " [ 8  3  7 ... 15 14 14]\n",
      " ...\n",
      " [ 0 12 11 ... 14 14 15]\n",
      " [ 8  6 11 ... 14 15 15]\n",
      " [12  0 11 ... 15 14 14]]\n",
      "(20, 108)\n"
     ]
    }
   ],
   "source": [
    "population[:10] = population[:10][permutation_index]\n",
    "print(population)\n",
    "print(population.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n"
     ]
    }
   ],
   "source": [
    "covariance = np.cov(population)\n",
    "print(covariance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n"
     ]
    }
   ],
   "source": [
    "covarmat_true = np.diag(np.diag(covariance))\n",
    "print(covarmat_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array 'mean' must be a vector of length 400.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-acccf2d65e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmvn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovarmat_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[1;32m    361\u001b[0m         return multivariate_normal_frozen(mean, cov,\n\u001b[1;32m    362\u001b[0m                                           \u001b[0mallow_singular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                                           seed=seed)\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultivariate_normal_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         self.dim, self.mean, self.cov = self._dist._process_parameters(\n\u001b[0;32m--> 735\u001b[0;31m                                                             None, mean, cov)\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxpts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m_process_parameters\u001b[0;34m(self, dim, mean, cov)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             raise ValueError(\"Array 'mean' must be a vector of length %d.\" %\n\u001b[0;32m--> 407\u001b[0;31m                              dim)\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Array 'mean' must be a vector of length 400."
     ]
    }
   ],
   "source": [
    " mvn = multivariate_normal(covariance, covarmat_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
